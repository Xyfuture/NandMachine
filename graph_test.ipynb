{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24cb9002",
   "metadata": {},
   "source": [
    "# Graph Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e902a159",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config loaded successfully:\n",
      "Hidden size: 4096\n",
      "Num attention heads: 32\n",
      "Num layers: 36\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import json\n",
    "import torch\n",
    "from transformers import Qwen3Config\n",
    "from nandmachine.frontend.network.qwen3 import Qwen3DecoderLayer\n",
    "from nandmachine.frontend.core.graph.base import NxTracer\n",
    "from nandmachine.frontend.network.torch_kernels import *\n",
    "\n",
    "# Load config from JSON\n",
    "with open('model_cards/qwen3-8B.json', 'r') as f:\n",
    "    config_dict = json.load(f)\n",
    "\n",
    "config = Qwen3Config(**config_dict)\n",
    "print(\"Config loaded successfully:\")\n",
    "print(f\"Hidden size: {config.hidden_size}\")\n",
    "print(f\"Num attention heads: {config.num_attention_heads}\")\n",
    "print(f\"Num layers: {config.num_hidden_layers}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33bd4a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch._subclasses.fake_tensor import FakeTensorMode\n",
    "from torch.fx.passes.fake_tensor_prop import FakeTensorProp\n",
    "\n",
    "\n",
    "fake_mode = FakeTensorMode(allow_non_fake_inputs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9fny7w7dl",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Qwen3DecoderLayer created successfully\n"
     ]
    }
   ],
   "source": [
    "# Create Qwen3DecoderLayer instance\n",
    "with fake_mode:\n",
    "    layer = Qwen3DecoderLayer(config)\n",
    "print(\"\\nQwen3DecoderLayer created successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "rufbin513ug",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tracing the computation graph...\n",
      "Graph traced successfully!\n",
      "Total nodes in graph: 57\n"
     ]
    }
   ],
   "source": [
    "# Trace the computation graph using NxTracer\n",
    "tracer = NxTracer()\n",
    "\n",
    "# Set the layer to eval mode to avoid training-specific behavior\n",
    "layer.eval()\n",
    "\n",
    "print(\"\\nTracing the computation graph...\")\n",
    "graph = tracer.trace(layer)\n",
    "gm = torch.fx.GraphModule(layer,graph)\n",
    "print(\"Graph traced successfully!\")\n",
    "print(f\"Total nodes in graph: {len(graph.nodes)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af157b72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "def forward(self, positions : torch.Tensor, hidden_states : torch.Tensor):\n",
      "    self_attn_qkv_proj_weight = self.self_attn.qkv_proj.weight\n",
      "    linear = torch._C._nn.linear(hidden_states, self_attn_qkv_proj_weight, None);  self_attn_qkv_proj_weight = None\n",
      "    split = linear.split([4096, 1024, 1024], dim = -1);  linear = None\n",
      "    getitem = split[0]\n",
      "    getitem_1 = split[1]\n",
      "    getitem_2 = split[2];  split = None\n",
      "    view = getitem.view(-1, 32, 128);  getitem = None\n",
      "    view_1 = getitem_1.view(-1, 8, 128);  getitem_1 = None\n",
      "    view_2 = getitem_2.view(-1, 8, 128);  getitem_2 = view_2 = None\n",
      "    self_attn_rotary_emb_cos_sin_cache = self.self_attn.rotary_emb.cos_sin_cache\n",
      "    getitem_3 = self_attn_rotary_emb_cos_sin_cache.__getitem__(positions);  self_attn_rotary_emb_cos_sin_cache = positions = None\n",
      "    chunk = getitem_3.chunk(2, dim = -1);  getitem_3 = None\n",
      "    getitem_4 = chunk[0]\n",
      "    getitem_5 = chunk[1];  chunk = None\n",
      "    float_1 = view.float()\n",
      "    chunk_1 = torch.chunk(float_1, 2, dim = -1);  float_1 = None\n",
      "    getitem_6 = chunk_1[0]\n",
      "    getitem_7 = chunk_1[1];  chunk_1 = None\n",
      "    mul = getitem_6 * getitem_4\n",
      "    mul_1 = getitem_7 * getitem_5\n",
      "    sub = mul - mul_1;  mul = mul_1 = None\n",
      "    mul_2 = getitem_7 * getitem_4;  getitem_7 = None\n",
      "    mul_3 = getitem_6 * getitem_5;  getitem_6 = None\n",
      "    add = mul_2 + mul_3;  mul_2 = mul_3 = None\n",
      "    cat = torch.cat((sub, add), dim = -1);  sub = add = None\n",
      "    getattr_1 = view.dtype;  view = None\n",
      "    to = cat.to(getattr_1);  cat = getattr_1 = None\n",
      "    float_2 = view_1.float()\n",
      "    chunk_2 = torch.chunk(float_2, 2, dim = -1);  float_2 = None\n",
      "    getitem_8 = chunk_2[0]\n",
      "    getitem_9 = chunk_2[1];  chunk_2 = None\n",
      "    mul_4 = getitem_8 * getitem_4\n",
      "    mul_5 = getitem_9 * getitem_5\n",
      "    sub_1 = mul_4 - mul_5;  mul_4 = mul_5 = None\n",
      "    mul_6 = getitem_9 * getitem_4;  getitem_9 = getitem_4 = None\n",
      "    mul_7 = getitem_8 * getitem_5;  getitem_8 = getitem_5 = None\n",
      "    add_1 = mul_6 + mul_7;  mul_6 = mul_7 = None\n",
      "    cat_1 = torch.cat((sub_1, add_1), dim = -1);  sub_1 = add_1 = None\n",
      "    getattr_2 = view_1.dtype;  view_1 = None\n",
      "    to_1 = cat_1.to(getattr_2);  cat_1 = getattr_2 = to_1 = None\n",
      "    add_2 = to + 1;  to = None\n",
      "    flatten = add_2.flatten(1, -1);  add_2 = None\n",
      "    self_attn_o_proj_weight = self.self_attn.o_proj.weight\n",
      "    linear_1 = torch._C._nn.linear(flatten, self_attn_o_proj_weight, None);  flatten = self_attn_o_proj_weight = None\n",
      "    add_3 = linear_1 + hidden_states;  linear_1 = hidden_states = None\n",
      "    mlp_gate_up_proj_weight = self.mlp.gate_up_proj.weight\n",
      "    linear_2 = torch._C._nn.linear(add_3, mlp_gate_up_proj_weight, None);  mlp_gate_up_proj_weight = None\n",
      "    chunk_3 = linear_2.chunk(2, -1);  linear_2 = None\n",
      "    getitem_10 = chunk_3[0]\n",
      "    getitem_11 = chunk_3[1];  chunk_3 = None\n",
      "    silu = torch.nn.functional.silu(getitem_10, inplace = False);  getitem_10 = None\n",
      "    mul_8 = silu * getitem_11;  silu = getitem_11 = None\n",
      "    mlp_down_proj_weight = self.mlp.down_proj.weight\n",
      "    linear_3 = torch._C._nn.linear(mul_8, mlp_down_proj_weight, None);  mul_8 = mlp_down_proj_weight = None\n",
      "    add_4 = linear_3 + add_3;  linear_3 = add_3 = add_4 = None\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(gm.code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b49e2995",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Node Shape Information After Fake Propagation ===\n",
      "Node: positions                      | Shape: torch.Size([16])     | Dtype: torch.int32\n",
      "Node: hidden_states                  | Shape: torch.Size([16, 1, 4096]) | Dtype: torch.float32\n",
      "Node: self_attn_qkv_proj_weight      | Shape: torch.Size([6144, 4096]) | Dtype: torch.float32\n",
      "Node: linear                         | Shape: torch.Size([16, 1, 6144]) | Dtype: torch.float32\n",
      "Node: split                          | Shape: N/A                  | Dtype: N/A\n",
      "Node: getitem                        | Shape: torch.Size([16, 1, 4096]) | Dtype: torch.float32\n",
      "Node: getitem_1                      | Shape: torch.Size([16, 1, 1024]) | Dtype: torch.float32\n",
      "Node: getitem_2                      | Shape: torch.Size([16, 1, 1024]) | Dtype: torch.float32\n",
      "Node: view                           | Shape: torch.Size([16, 32, 128]) | Dtype: torch.float32\n",
      "Node: view_1                         | Shape: torch.Size([16, 8, 128]) | Dtype: torch.float32\n",
      "Node: view_2                         | Shape: torch.Size([16, 8, 128]) | Dtype: torch.float32\n",
      "Node: self_attn_rotary_emb_cos_sin_cache | Shape: torch.Size([40960, 1, 128]) | Dtype: torch.float32\n",
      "Node: getitem_3                      | Shape: torch.Size([16, 1, 128]) | Dtype: torch.float32\n",
      "Node: chunk                          | Shape: N/A                  | Dtype: N/A\n",
      "Node: getitem_4                      | Shape: torch.Size([16, 1, 64]) | Dtype: torch.float32\n",
      "Node: getitem_5                      | Shape: torch.Size([16, 1, 64]) | Dtype: torch.float32\n",
      "Node: float_1                        | Shape: torch.Size([16, 32, 128]) | Dtype: torch.float32\n",
      "Node: chunk_1                        | Shape: N/A                  | Dtype: N/A\n",
      "Node: getitem_6                      | Shape: torch.Size([16, 32, 64]) | Dtype: torch.float32\n",
      "Node: getitem_7                      | Shape: torch.Size([16, 32, 64]) | Dtype: torch.float32\n",
      "Node: mul                            | Shape: torch.Size([16, 32, 64]) | Dtype: torch.float32\n",
      "Node: mul_1                          | Shape: torch.Size([16, 32, 64]) | Dtype: torch.float32\n",
      "Node: sub                            | Shape: torch.Size([16, 32, 64]) | Dtype: torch.float32\n",
      "Node: mul_2                          | Shape: torch.Size([16, 32, 64]) | Dtype: torch.float32\n",
      "Node: mul_3                          | Shape: torch.Size([16, 32, 64]) | Dtype: torch.float32\n",
      "Node: add                            | Shape: torch.Size([16, 32, 64]) | Dtype: torch.float32\n",
      "Node: cat                            | Shape: torch.Size([16, 32, 128]) | Dtype: torch.float32\n",
      "Node: getattr_1                      | Shape: N/A                | Dtype: N/A\n",
      "Node: to                             | Shape: torch.Size([16, 32, 128]) | Dtype: torch.float32\n",
      "Node: float_2                        | Shape: torch.Size([16, 8, 128]) | Dtype: torch.float32\n",
      "Node: chunk_2                        | Shape: N/A                  | Dtype: N/A\n",
      "Node: getitem_8                      | Shape: torch.Size([16, 8, 64]) | Dtype: torch.float32\n",
      "Node: getitem_9                      | Shape: torch.Size([16, 8, 64]) | Dtype: torch.float32\n",
      "Node: mul_4                          | Shape: torch.Size([16, 8, 64]) | Dtype: torch.float32\n",
      "Node: mul_5                          | Shape: torch.Size([16, 8, 64]) | Dtype: torch.float32\n",
      "Node: sub_1                          | Shape: torch.Size([16, 8, 64]) | Dtype: torch.float32\n",
      "Node: mul_6                          | Shape: torch.Size([16, 8, 64]) | Dtype: torch.float32\n",
      "Node: mul_7                          | Shape: torch.Size([16, 8, 64]) | Dtype: torch.float32\n",
      "Node: add_1                          | Shape: torch.Size([16, 8, 64]) | Dtype: torch.float32\n",
      "Node: cat_1                          | Shape: torch.Size([16, 8, 128]) | Dtype: torch.float32\n",
      "Node: getattr_2                      | Shape: N/A                | Dtype: N/A\n",
      "Node: to_1                           | Shape: torch.Size([16, 8, 128]) | Dtype: torch.float32\n",
      "Node: add_2                          | Shape: torch.Size([16, 32, 128]) | Dtype: torch.float32\n",
      "Node: flatten                        | Shape: torch.Size([16, 4096]) | Dtype: torch.float32\n",
      "Node: self_attn_o_proj_weight        | Shape: torch.Size([4096, 4096]) | Dtype: torch.float32\n",
      "Node: linear_1                       | Shape: torch.Size([16, 4096]) | Dtype: torch.float32\n",
      "Node: add_3                          | Shape: torch.Size([16, 16, 4096]) | Dtype: torch.float32\n",
      "Node: mlp_gate_up_proj_weight        | Shape: torch.Size([24576, 4096]) | Dtype: torch.float32\n",
      "Node: linear_2                       | Shape: torch.Size([16, 16, 24576]) | Dtype: torch.float32\n",
      "Node: chunk_3                        | Shape: N/A                  | Dtype: N/A\n",
      "Node: getitem_10                     | Shape: torch.Size([16, 16, 12288]) | Dtype: torch.float32\n",
      "Node: getitem_11                     | Shape: torch.Size([16, 16, 12288]) | Dtype: torch.float32\n",
      "Node: silu                           | Shape: torch.Size([16, 16, 12288]) | Dtype: torch.float32\n",
      "Node: mul_8                          | Shape: torch.Size([16, 16, 12288]) | Dtype: torch.float32\n",
      "Node: mlp_down_proj_weight           | Shape: torch.Size([4096, 12288]) | Dtype: torch.float32\n",
      "Node: linear_3                       | Shape: torch.Size([16, 16, 4096]) | Dtype: torch.float32\n",
      "Node: add_4                          | Shape: torch.Size([16, 16, 4096]) | Dtype: torch.float32\n"
     ]
    }
   ],
   "source": [
    "with fake_mode:\n",
    "    input_hidden_states = torch.empty([16,1,4096])\n",
    "    input_position = torch.empty([16],dtype=torch.int)\n",
    "\n",
    "\n",
    "fake_prop = FakeTensorProp(gm,mode=fake_mode)\n",
    "\n",
    "fake_prop.propagate(input_position,input_hidden_states)\n",
    "\n",
    "# Print shape information for each node\n",
    "print(\"\\n=== Node Shape Information After Fake Propagation ===\")\n",
    "for node in gm.graph.nodes:\n",
    "    if hasattr(node, 'meta') and 'val' in node.meta:\n",
    "        val = node.meta['val']\n",
    "        if val is not None:\n",
    "            shape = val.shape if hasattr(val, 'shape') else 'N/A'\n",
    "            dtype = val.dtype if hasattr(val, 'dtype') else 'N/A'\n",
    "            print(f\"Node: {node.name:30s} | Shape: {str(shape):20s} | Dtype: {dtype}\")\n",
    "        else:\n",
    "            print(f\"Node: {node.name:30s} | Shape: N/A                | Dtype: N/A\")\n",
    "    else:\n",
    "        print(f\"Node: {node.name:30s} | Shape: N/A                | Dtype: N/A\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1d4fc610",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FakeTensor(..., size=(16, 16, 4096), grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer(input_position, input_hidden_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8ff4b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda: machine",
   "language": "python",
   "name": "machine"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
